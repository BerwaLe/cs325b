{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas\n",
    "import skimage\n",
    "import shapefile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenya_osm, kenya_sf = modules.data.load_shapefile(\"kenya\")\n",
    "kenya_geo = modules.data.load_geodata(\"kenya\")\n",
    "kenya_dat = pandas.DataFrame.merge(kenya_geo, kenya_osm, on=\"index\")\n",
    "\n",
    "kenya_filenames = set(modules.data.util.load_image_filenames(\"kenya\", D=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "\n",
    "kenya_dat[kenya_dat[\"class\"] == \"major\"]\n",
    "kenya_dat[kenya_dat[\"class\"] == \"minor\"]\n",
    "kenya_dat[kenya_dat[\"class\"] == \"two-track\"]\n",
    "kenya_dat[\"valid\"] = [f\"{int(index)}_{int(road_id)}.npy\" in kenya_filenames for index, road_id in enumerate(kenya_dat.values[:, 0])]\n",
    "\n",
    "major = kenya_dat.iloc[np.random.choice(kenya_dat[np.logical_and(kenya_dat[\"class\"] == \"major\", kenya_dat[\"valid\"] == True)].index, size=N, replace=False)]\n",
    "minor = kenya_dat.iloc[np.random.choice(kenya_dat[np.logical_and(kenya_dat[\"class\"] == \"minor\", kenya_dat[\"valid\"] == True)].index, size=N, replace=False)]\n",
    "two_track = kenya_dat.iloc[np.random.choice(kenya_dat[np.logical_and(kenya_dat[\"class\"] == \"two-track\", kenya_dat[\"valid\"] == True)].index, size=N, replace=False)]\n",
    "\n",
    "filenames = [f\"{idx}_{int(df.loc[idx]['id'])}.npy\" for df in [major, minor, two_track] for idx in df.index]\n",
    "permutation = np.arange(len(filenames))\n",
    "np.random.shuffle(permutation)\n",
    "\n",
    "images = [np.load(os.path.join(modules.data.util.root(), \"kenya\", \"kenya_128x128_images\", filenames[i])) for i in permutation]\n",
    "images = np.array(images)\n",
    "labels = permutation // N\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "def _SIFT(image, sift, plot=False):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints = sift.detect(image, None)\n",
    "    if plot:\n",
    "        plt.imshow(cv2.drawKeypoints(image, keypoints, outImage=np.array([])))\n",
    "    return keypoints\n",
    "\n",
    "def SIFT(images):\n",
    "    keypoints = []\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    for image in images:\n",
    "        kpts = _SIFT(image, sift)\n",
    "        keypoints.append(kpts)\n",
    "    return keypoints\n",
    "\n",
    "sift = SIFT(images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def HOG(images):\n",
    "    features = []\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    for image in images:\n",
    "        features.append(hog.compute(image))\n",
    "    return features\n",
    "\n",
    "hog = HOG(images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def Canny(images):\n",
    "    channels = []\n",
    "    for image in images:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        median = np.median(gray)\n",
    "        channel = cv2.Canny(gray, (1/2) * median, (2) * median, apertureSize=3)[:, :, None]\n",
    "        channels.append(channel)\n",
    "    return np.array(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def location(df, fnames):\n",
    "    locations = []\n",
    "    for fname in fnames:\n",
    "        index = fname.split(\"_\")[0]\n",
    "        locations.append(df.loc[int(index)][[\"lat\", \"lon\"]].values.astype(np.float64))\n",
    "    return np.array(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_mean(images):\n",
    "    return np.mean(images, axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_variance(images):\n",
    "    return np.mean(np.power(images - np.mean(images, axis=(1, 2))[:, None, None, :], 2), axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_set(images):\n",
    "    canny = Canny(images)\n",
    "\n",
    "    locations = location(kenya_dat, filenames)\n",
    "    rgb_means = channel_mean(images)\n",
    "    rgb_variances = channel_variance(canny)\n",
    "    canny_means = channel_mean(images)\n",
    "    canny_variances = channel_variance(canny)\n",
    "    \n",
    "    return np.concatenate([\n",
    "        locations,\n",
    "        rgb_means,\n",
    "        rgb_variances,\n",
    "        canny_means,\n",
    "        canny_variances\n",
    "    ], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch (1, 1)\n",
      "Patch (1, 43)\n",
      "Patch (1, 85)\n",
      "Patch (43, 1)\n",
      "Patch (43, 43)\n",
      "Patch (43, 85)\n",
      "Patch (85, 1)\n",
      "Patch (85, 43)\n",
      "Patch (85, 85)\n"
     ]
    }
   ],
   "source": [
    "features = feature_set(images)\n",
    "for i in range(0+1, 128-1, 128//3):\n",
    "    for j in range(0+1, 128-1, 128//3):\n",
    "        print(f\"Patch ({i}, {j})\")\n",
    "        patches = images[:, i:i+128//3, j:j+128//3, :]\n",
    "        features = np.concatenate([features, feature_set(patches)], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score, f1_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(classifier, X_train, y_train, X_test, y_test, verbose=True):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    scores = [r2_score(y_test, y_pred), \n",
    "              accuracy_score(y_test, y_pred), \n",
    "              f1_score(y_test, y_pred, average=None),\n",
    "              log_loss(y_test, y_pred)\n",
    "             ]\n",
    "    if verbose:\n",
    "        print(f\"r^2: {scores[0]}\")\n",
    "        print(f\"accuracy: {scores[1]}\")\n",
    "        print(f\"f1: {scores[2]}\")\n",
    "    return classifier, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((810, 100), (810,), (0, 100), (90,))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff = features.shape[0] * 9 // 10\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features[:cutoff])\n",
    "\n",
    "X_train = scaled_features[:cutoff]\n",
    "y_train = labels[:cutoff]\n",
    "X_test = scaled_features[cutoff:]\n",
    "y_test = labels[cutoff:]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various classifiers of interest implemented by SKLearn\n",
    "log_classifier = linear_model.LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "svm_classifier = svm.SVC(kernel='rbf', gamma=\"auto\")\n",
    "k_classifier = KNeighborsClassifier(n_neighbors=6)\n",
    "tree_classifier = tree.DecisionTreeClassifier()\n",
    "rf_classifier = ensemble.RandomForestClassifier(n_estimators=500)\n",
    "boost_classifier = ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john_kamalu/miniconda3/envs/roads/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 100)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-fa9d4a373f63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-518f2a596b21>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(classifier, X_train, y_train, X_test, y_test, verbose)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     scores = [r2_score(y_test, y_pred), \n\u001b[1;32m      5\u001b[0m               \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/roads/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/roads/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    263\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/roads/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    548\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 550\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 100)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "_, _ = test(log_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2: -1.6315789473684212\n",
      "accuracy: 0.3111111111111111\n",
      "f1: [0.         0.         0.47457627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john_kamalu/miniconda3/envs/roads/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "_, _ = test(svm_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2: -0.7826825127334467\n",
      "accuracy: 0.4\n",
      "f1: [0.41935484 0.37288136 0.40677966]\n"
     ]
    }
   ],
   "source": [
    "_, _ = test(k_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2: -0.12054329371816652\n",
      "accuracy: 0.4666666666666667\n",
      "f1: [0.62068966 0.3        0.48387097]\n"
     ]
    }
   ],
   "source": [
    "_, _ = test(tree_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2: -0.2903225806451615\n",
      "accuracy: 0.4888888888888889\n",
      "f1: [0.57142857 0.4        0.5       ]\n"
     ]
    }
   ],
   "source": [
    "_, _ = test(rf_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2: -0.5959252971137523\n",
      "accuracy: 0.4222222222222222\n",
      "f1: [0.53571429 0.32142857 0.41176471]\n"
     ]
    }
   ],
   "source": [
    "_, _ = test(boost_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
