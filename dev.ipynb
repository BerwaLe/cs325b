{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas\n",
    "import skimage\n",
    "import shapefile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenya_osm, kenya_sf = modules.data.load_shapefile(\"kenya\")\n",
    "kenya_geo = modules.data.load_geodata(\"kenya\")\n",
    "kenya_dat = pandas.DataFrame.merge(kenya_geo, kenya_osm, on=\"index\")\n",
    "\n",
    "kenya_filenames = set(modules.data.util.load_image_filenames(\"kenya\", D=128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300\n",
    "\n",
    "kenya_dat[kenya_dat[\"class\"] == \"major\"]\n",
    "kenya_dat[kenya_dat[\"class\"] == \"minor\"]\n",
    "kenya_dat[kenya_dat[\"class\"] == \"two-track\"]\n",
    "kenya_dat[\"valid\"] = [f\"{int(index)}_{int(road_id)}.npy\" in kenya_filenames for index, road_id in enumerate(kenya_dat.values[:, 0])]\n",
    "\n",
    "major = kenya_dat.iloc[np.random.choice(kenya_dat[np.logical_and(kenya_dat[\"class\"] == \"major\", kenya_dat[\"valid\"] == True)].index, size=N, replace=False)]\n",
    "minor = kenya_dat.iloc[np.random.choice(kenya_dat[np.logical_and(kenya_dat[\"class\"] == \"minor\", kenya_dat[\"valid\"] == True)].index, size=N, replace=False)]\n",
    "two_track = kenya_dat.iloc[np.random.choice(kenya_dat[np.logical_and(kenya_dat[\"class\"] == \"two-track\", kenya_dat[\"valid\"] == True)].index, size=N, replace=False)]\n",
    "\n",
    "filenames = [f\"{idx}_{int(df.loc[idx]['id'])}.npy\" for df in [major, minor, two_track] for idx in df.index]\n",
    "permutation = np.arange(len(filenames))\n",
    "np.random.shuffle(permutation)\n",
    "\n",
    "images = [np.load(os.path.join(modules.data.util.root(), \"kenya\", \"kenya_128x128_images\", filenames[i])) for i in permutation]\n",
    "images = np.array(images)\n",
    "labels = permutation // N\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "def _SIFT(image, sift, plot=False):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints = sift.detect(image, None)\n",
    "    if plot:\n",
    "        plt.imshow(cv2.drawKeypoints(image, keypoints, outImage=np.array([])))\n",
    "    return keypoints\n",
    "\n",
    "def SIFT(images):\n",
    "    keypoints = []\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    for image in images:\n",
    "        kpts = _SIFT(image, sift)\n",
    "        keypoints.append(kpts)\n",
    "    return keypoints\n",
    "\n",
    "sift = SIFT(images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def HOG(images):\n",
    "    features = []\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    for image in images:\n",
    "        features.append(hog.compute(image))\n",
    "    return features\n",
    "\n",
    "hog = HOG(images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def Canny(images):\n",
    "    channels = []\n",
    "    for image in images:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        median = np.median(gray)\n",
    "        channel = cv2.Canny(gray, (1/2) * median, (2) * median, apertureSize=3)[:, :, None]\n",
    "        channels.append(channel)\n",
    "    return np.array(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def location(df, fnames):\n",
    "    locations = []\n",
    "    for fname in fnames:\n",
    "        index = fname.split(\"_\")[0]\n",
    "        locations.append(df.loc[int(index)][[\"lat\", \"lon\"]].values.astype(np.float64))\n",
    "    return np.array(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_mean(images):\n",
    "    return np.mean(images, axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def channel_variance(images):\n",
    "    return np.mean(np.power(images - np.mean(images, axis=(1, 2))[:, None, None, :], 2), axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_set(images):\n",
    "    canny = Canny(images)\n",
    "\n",
    "    locations = location(kenya_dat, filenames)\n",
    "    rgb_means = channel_mean(images)\n",
    "    rgb_variances = channel_variance(canny)\n",
    "    canny_means = channel_mean(images)\n",
    "    canny_variances = channel_variance(canny)\n",
    "    \n",
    "    return np.concatenate([\n",
    "        locations,\n",
    "        rgb_means,\n",
    "        rgb_variances,\n",
    "        canny_means,\n",
    "        canny_variances\n",
    "    ], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_set(images)\n",
    "for i in range(0+1, 128-1, 128//3):\n",
    "    for j in range(0+1, 128-1, 128//3):\n",
    "        print(f\"Patch ({i}, {j})\")\n",
    "        patches = images[:, i:i+128//3, j:j+128//3, :]\n",
    "        features = np.concatenate([features, feature_set(patches)], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score, f1_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(classifier, X_train, y_train, X_test, y_test, verbose=True):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    val_scores = [r2_score(y_test, y_pred), \n",
    "              accuracy_score(y_test, y_pred), \n",
    "              f1_score(y_test, y_pred, average=None),\n",
    "             ]\n",
    "    y_pred = classifier.predict(X_train)\n",
    "    train_scores = [r2_score(y_train, y_pred), \n",
    "              accuracy_score(y_train, y_pred), \n",
    "              f1_score(y_train, y_pred, average=None),\n",
    "             ]\n",
    "    if verbose:\n",
    "        print(\"val\")\n",
    "        print(f\"r^2: {val_scores[0]}\")\n",
    "        print(f\"accuracy: {val_scores[1]}\")\n",
    "        print(f\"f1: {val_scores[2]}\")\n",
    "        print(\"train\")\n",
    "        print(f\"r^2: {train_scores[0]}\")\n",
    "        print(f\"accuracy: {train_scores[1]}\")\n",
    "        print(f\"f1: {train_scores[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = features.shape[0] * 9 // 10\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(features[:cutoff])\n",
    "\n",
    "scaled_features = scaler.transform(features)\n",
    "X_train = scaled_features[:cutoff]\n",
    "y_train = labels[:cutoff]\n",
    "X_test = scaled_features[cutoff:]\n",
    "y_test = labels[cutoff:]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various classifiers of interest implemented by SKLearn\n",
    "log_classifier = linear_model.LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "svm_classifier = svm.SVC(kernel='rbf', gamma=\"auto\")\n",
    "k_classifier = KNeighborsClassifier(n_neighbors=6)\n",
    "tree_classifier = tree.DecisionTreeClassifier()\n",
    "rf_classifier = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "boost_classifier = ensemble.GradientBoostingClassifier()\n",
    "nn_classifier = MLPClassifier(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(log_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(svm_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(k_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(tree_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(rf_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(boost_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(nn_classifier, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
