{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas\n",
    "import skimage\n",
    "import sklearn\n",
    "import shapefile\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rescale images to workable size (low priority -- use ben's for now)\n",
    "\n",
    "# TODO: filter unwanted samples e.g. clouds, outliers, etc. (low priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = modules.run.load_config(\"cls\", tag=\"w5\")\n",
    "\n",
    "dg = modules.data.DatasetGenerator(config)\n",
    "dg._setup(\"kenya\")\n",
    "\n",
    "checkpoints_dir = os.path.join(\"data\", config[\"base\"] + config[\"tag\"], \"checkpoints\")\n",
    "if not os.path.isdir(checkpoints_dir):\n",
    "    os.makedirs(checkpoints_dir)\n",
    "\n",
    "tensorboard_dir = os.path.join(\"data\", config[\"base\"] + config[\"tag\"], \"tensorboard\")\n",
    "if not os.path.isdir(tensorboard_dir):\n",
    "    os.makedirs(tensorboard_dir)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    tensorboard_dir, \n",
    "    histogram_freq=1,\n",
    "    write_graph=True, \n",
    "    write_images=True,\n",
    "    update_freq=config[\"batch_size\"] * config[\"tensorboard_freq\"]\n",
    ")\n",
    "\n",
    "checkpoints_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    f\"{checkpoints_dir}/model\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    ")\n",
    "\n",
    "input_layer = tf.keras.layers.Input(\n",
    "    shape=(\n",
    "        config[\"image_size\"],\n",
    "        config[\"image_size\"],\n",
    "        config[\"n_channels\"])\n",
    ")\n",
    "\n",
    "vgg16 = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=input_layer,\n",
    "    pooling=\"max\",\n",
    "    classes=config[\"n_classes\"]\n",
    ")\n",
    "\n",
    "cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "\n",
    "if config[\"balance_classes\"]:\n",
    "    class_weight = sklearn.utils.class_weight.compute_class_weight(\n",
    "        \"balanced\", \n",
    "        list(range(config[\"n_classes\"])), \n",
    "        [config[\"class_enum\"][v] for v in dg.dataframes[\"kenya\"][\"class\"].values]\n",
    "    )\n",
    "else:\n",
    "    class_weight = None\n",
    "    \n",
    "vgg16.compile(loss=cce_loss, optimizer=adam_opt)\n",
    "\n",
    "vgg16.summary()\n",
    "\n",
    "vgg16.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=config[\"n_epochs\"],\n",
    "    callbacks=[tensorboard_callback, checkpoints_callback], \n",
    "    validation_data=val_generator, \n",
    "    validation_steps=len(val_generator) // config[\"batch_size\"],\n",
    "    class_weight=class_weight\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
